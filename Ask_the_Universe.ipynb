{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPowpwoaq59pE505vLwfXbO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dakshitasharma/Ask-the-Universe---NASA-RAG-Chatbot-with-LangChain-Gemini-and-Hugging-Face/blob/main/Ask_the_Universe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ljdbaJ-A7-vh"
      },
      "outputs": [],
      "source": [
        "#Install all the packages\n",
        "\n",
        "\n",
        "#!pip install streamlit pyngrok langchain langchain_google_genai langchain_community chromadb faiss-cpu huggingface-hub google-generativeai --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "GOOGLE_API_KEY=\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaNxRRoKiJCU",
        "outputId": "a82702c5-2349-42dd-924a-984b63e1f339"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a app.py file to so that we can integrate it with Stramlit app"
      ],
      "metadata": {
        "id": "KCR6I_XfRe4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Import the liberary\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "import os\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "import google.generativeai as genai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load API keys\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "GEMINI_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "#  KEYS (Replace with your keys)\n",
        "\n",
        "#GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# ðŸ”¹ Configure Gemini\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GEMINI_API_KEY)\n",
        "\n",
        "# ðŸ”¹ Hugging Face Embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# ðŸ”¹ NASA API Fetch\n",
        "def get_nasa_data(query):\n",
        "    url = f\"https://images-api.nasa.gov/search?q={query}\"\n",
        "    try:\n",
        "        response = requests.get(url).json()\n",
        "\n",
        "        # ðŸ” Print the raw NASA response (just first item)\n",
        "        items = response.get(\"collection\", {}).get(\"items\", [])\n",
        "        print(f\"ðŸ” NASA returned {len(items)} results\")\n",
        "        if items:\n",
        "            print(f\"Sample NASA item: {items[0]}\")\n",
        "\n",
        "        docs = []\n",
        "        for item in items[:30]:  # Only top 3 results\n",
        "            title = item[\"data\"][0][\"title\"]\n",
        "            desc = item[\"data\"][0].get(\"description\", \"\")\n",
        "            text = f\"{title}\\n{desc}\"\n",
        "            docs.append(Document(page_content=text))\n",
        "\n",
        "        return docs\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching NASA data: {e}\")\n",
        "        return []\n",
        "# ðŸ”¹ Build FAISS VectorStore\n",
        "def build_vectorstore(docs):\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    splits = splitter.split_documents(docs)\n",
        "    return FAISS.from_documents(splits, embeddings)\n",
        "\n",
        "# ðŸ”¹ RAG Pipeline\n",
        "def ask_universe(question):\n",
        "    nasa_docs = get_nasa_data(question)\n",
        "    if not nasa_docs:\n",
        "        return \"No NASA data found.\"\n",
        "    vs = build_vectorstore(nasa_docs)\n",
        "    retriever = vs.as_retriever()\n",
        "    qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "    return qa.run(question)\n",
        "\n",
        "# ðŸ”¹ Streamlit App\n",
        "st.set_page_config(page_title=\"Ask the Universe\", page_icon=\"ðŸš€\")\n",
        "st.title(\"ðŸš€ Ask the Universe (NASA + LangChain RAG)\")\n",
        "st.write(\"Ask me anything about space! Iâ€™ll fetch NASA data and answer using Gemini.\")\n",
        "\n",
        "query = st.text_input(\"ðŸ”­ Enter your space question:\")\n",
        "if st.button(\"Ask\"):\n",
        "    if query.strip():\n",
        "        with st.spinner(\"Contacting NASA & thinking...\"):\n",
        "            answer = ask_universe(query)\n",
        "        st.markdown(f\"### ðŸŒŒ Answer:\\n{answer}\")\n",
        "    else:\n",
        "        st.warning(\"Please enter a question!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAHNgN8J8Udv",
        "outputId": "628d28c5-5b88-47e9-85ce-ebb7fbce9ad2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a link by using ngrok which can run app.py"
      ],
      "metadata": {
        "id": "bIzDyFI-SSTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Set your ngrok token\n",
        "\n",
        "NGROK_TOKEN=userdata.get('NGROK_TOKEN')\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# Start Streamlit\n",
        "!nohup streamlit run app.py --server.port 8501 > /dev/null 2>&1 &\n",
        "time.sleep(3)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"ðŸŒ Your RAG App is live here: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vaQYLsP8Edr",
        "outputId": "7cde30c2-764d-4ba0-ff8a-43d52cf28c18"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ Your RAG App is live here: NgrokTunnel: \"https://2d2edf981e25.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}
